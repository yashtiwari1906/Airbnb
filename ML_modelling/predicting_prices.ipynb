{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold,RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('newyork_airbnb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we will convert amenities column ie. we will extract every single values and then join them to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an array with the features we want to keep.\n",
    "selected_features = ['name', 'neighbourhood_cleansed', 'room_type', 'guests_included', 'minimum_nights',\n",
    "                     'number_of_reviews', 'review_scores_rating', 'amenities', 'property_type',\n",
    "                     'accommodates', 'bathrooms', 'bedrooms', 'beds', 'bed_type', 'price']\n",
    "selected_df= df.copy()[selected_features]\n",
    "selected_df.rename(columns = {'neighbourhood_cleansed':'neighbourhood'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df['price']=selected_df['price'].apply(lambda x: x.replace('$',''))\n",
    "selected_df['price']=selected_df['price'].apply(lambda x: float(x.replace(',','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##%%time\n",
    "regex = r\"{([^}]*)}\"\n",
    "regex2 = r\"translation.\\w\\D+..\"\n",
    "listings_cp = selected_df.copy()\n",
    "listings_cp['amenities'] = selected_df['amenities'].map(lambda amns: re.search(regex, amns).group(1))\n",
    "listings_cp['amenities'] = selected_df['amenities'].map(lambda amns: re.sub(regex2, '', amns))\n",
    "listings_cp['amenities'] = selected_df['amenities'].map(lambda amns: amns.replace(\"\\\"\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The code for adding the amenities colums is currently commented for practicality\n",
    "#amenity_ohe = listings_cp.amenities.str.get_dummies(sep = \",\")\n",
    "#amenities_cols = amenity_ohe.columns.values\n",
    "# dataset = pd.concat([listings_cp, amenity_ohe], axis=1)\n",
    "dataset = selected_df.query('price <= 500')\n",
    "dataset = dataset.drop('amenities', axis=1)\n",
    "dataset = dataset.drop('name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood               0\n",
       "room_type                   0\n",
       "guests_included             0\n",
       "minimum_nights              0\n",
       "number_of_reviews           0\n",
       "review_scores_rating    21944\n",
       "property_type               0\n",
       "accommodates                0\n",
       "bathrooms                 129\n",
       "bedrooms                  148\n",
       "beds                      928\n",
       "bed_type                    3\n",
       "price                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Null Values  \n",
    "\n",
    "Since there was many empty columns in our dataset so we have to treat them before fitting to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The numeric features that present null values are: review_scores_rating, bathrooms, bedrooms\n",
    "# and beds from previous notebook https://github.com/Summi-bhai/Airbnb_dataset/blob/master/Analysis_Part_1.ipynb\n",
    "\n",
    "dataset['review_scores_rating'] = dataset['review_scores_rating'].fillna(dataset['review_scores_rating'].median())\n",
    "dataset['bathrooms'] = dataset['bathrooms'].fillna(dataset['bathrooms'].median())\n",
    "dataset['bedrooms'] = dataset['bedrooms'].fillna(dataset['bedrooms'].median())\n",
    "dataset['beds'] = dataset['beds'].fillna(dataset['beds'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting categorical features to float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood            object\n",
       "room_type                object\n",
       "guests_included           int64\n",
       "minimum_nights            int64\n",
       "number_of_reviews         int64\n",
       "review_scores_rating    float64\n",
       "property_type            object\n",
       "accommodates              int64\n",
       "bathrooms               float64\n",
       "bedrooms                float64\n",
       "beds                    float64\n",
       "bed_type                 object\n",
       "price                   float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood           float64\n",
       "room_type               float64\n",
       "guests_included         float64\n",
       "minimum_nights          float64\n",
       "number_of_reviews       float64\n",
       "review_scores_rating    float64\n",
       "property_type           float64\n",
       "accommodates            float64\n",
       "bathrooms               float64\n",
       "bedrooms                float64\n",
       "beds                    float64\n",
       "bed_type                float64\n",
       "price                   float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# it was showing error with bed_type that's why we will be handling it by our hands\n",
    "cat_columns = ['neighbourhood', 'room_type', 'property_type','bed_type']\n",
    "encoder=LabelEncoder()\n",
    "for col in cat_columns:\n",
    "    dataset[col]=encoder.fit_transform(dataset[col])\n",
    "\n",
    "# converting features to float\n",
    "dataset = dataset.astype(float)\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dataset['price']\n",
    "dataset.drop('price',axis=1,inplace=True)\n",
    "\n",
    "X=dataset\n",
    "\n",
    "# now we have training,validation and test data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1)\n",
    "X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to define .fit() and cross-validation methods then we will fit different different models of regression from sklearn library and then finally use randomized search cv for better hyper-parameter choice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_model(model,X_train, y_train, X_val, y_val, cross_val=False, cv_folds=5):\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    #Predict values:\n",
    "    training_predictions = model.predict(X_train)\n",
    "    validation_predictions = model.predict(X_val)\n",
    "    model_report(X_train,y_train, X_val,y_val, training_predictions, validation_predictions)\n",
    "\n",
    "    if cross_val:\n",
    "        evaluate_cross_validation(model, X_train, y_train, cv_folds)\n",
    "        \n",
    "def model_report(X_train,y_train, X_val,y_val, training_predictions, validation_predictions):\n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Training\")\n",
    "    print(\"Mean Absolute Error : {}\".format(mean_absolute_error(y_train, training_predictions)))\n",
    "    print(\"Root Mean Squared Error : {}\".format(np.sqrt(mean_squared_error(y_train, training_predictions))))\n",
    "    print(\"R2 Score: {}\".format(r2_score(y_train, training_predictions)))\n",
    "    print(\"\\n\")\n",
    "    print(\"Validation\")\n",
    "    print(\"Mean Absolute Error : {}\".format(mean_absolute_error(y_val, validation_predictions)))\n",
    "    print(\"Root Mean Squared Error : {}\".format(np.sqrt(mean_squared_error(y_val, validation_predictions))))\n",
    "    print(\"R2 Score: {}\".format(r2_score(y_val, validation_predictions)))\n",
    "    \n",
    "def evaluate_cross_validation(model, X_train, y_train, K):\n",
    "    \n",
    "    cv = KFold(n_splits=K, shuffle=True, random_state=2)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv)\n",
    "    print()\n",
    "    print(scores)\n",
    "    print(\"Mean score: {} max is {} and min {}\".format(scores.mean(), max(scores), min(scores)))   \n",
    "    \n",
    "def random_search(model, param_grid, X_train, y_train, X_val, y_val, cv):\n",
    "    \n",
    "    random_search = RandomizedSearchCV(model, param_grid, scoring=\"neg_mean_squared_error\", n_jobs=2, cv=cv)\n",
    "    random_result = random_search.fit(X_train, y_train)\n",
    "\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "    means = random_result.cv_results_['mean_test_score']\n",
    "    stds = random_result.cv_results_['std_test_score']\n",
    "    params = random_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "    validation_predictions = random_result.predict(X_val)\n",
    "\n",
    "    print(\"Validation\")\n",
    "    print(\"Mean Absolute Error : {}\".format(mean_absolute_error(y_val, validation_predictions)))\n",
    "    print(\"Root Mean Squared Error : {}\".format(np.sqrt(mean_squared_error(y_val, validation_predictions))))\n",
    "    print(\"R2 Score: {}\".format(r2_score(y_val, validation_predictions)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection and training\n",
    "\n",
    " For now we will fit are dataset on Decision tree and Random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Training\n",
      "Mean Absolute Error : 1.6937544060822054\n",
      "Root Mean Squared Error : 9.581057727365469\n",
      "R2 Score: 0.9849578951020708\n",
      "\n",
      "\n",
      "Validation\n",
      "Mean Absolute Error : 41.120209817936725\n",
      "Root Mean Squared Error : 68.36990010850042\n",
      "R2 Score: 0.1951965059466796\n",
      "\n",
      "[0.23128123 0.17649688 0.19420428 0.20902082 0.24359383]\n",
      "Mean score: 0.21091941202938597 max is 0.2435938348100085 and min 0.17649688354975582\n"
     ]
    }
   ],
   "source": [
    "model=DecisionTreeRegressor(random_state=8)\n",
    "fit_model(model,X_train,y_train,X_val,y_val,cross_val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Training\n",
      "Mean Absolute Error : 13.56358851626989\n",
      "Root Mean Squared Error : 23.385464970966563\n",
      "R2 Score: 0.9103864425891506\n",
      "\n",
      "\n",
      "Validation\n",
      "Mean Absolute Error : 32.35069227134165\n",
      "Root Mean Squared Error : 51.88226528137649\n",
      "R2 Score: 0.5365554040316143\n",
      "\n",
      "[0.54479998 0.52522746 0.54135664 0.54315833 0.54033323]\n",
      "Mean score: 0.5389751289772429 max is 0.5447999844928277 and min 0.5252274642306107\n"
     ]
    }
   ],
   "source": [
    "model=RandomForestRegressor()\n",
    "fit_model(model,X_train,y_train,X_val,y_val,cross_val=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Now we had dry runned our model over default parameters but however unfortunately our model overfitted the data so now we will tune our parameters with the help of random search cv we will only using random search for decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -2688.065789 using {'min_samples_leaf': 70, 'max_features': 'auto', 'max_depth': 10}\n",
      "-2698.475869 (104.469392) with: {'min_samples_leaf': 100, 'max_features': 'auto', 'max_depth': 10}\n",
      "-3008.774149 (145.895530) with: {'min_samples_leaf': 70, 'max_features': 'sqrt', 'max_depth': 10}\n",
      "-3001.631794 (153.043338) with: {'min_samples_leaf': 100, 'max_features': 'log2', 'max_depth': 15}\n",
      "-2688.065789 (114.498584) with: {'min_samples_leaf': 70, 'max_features': 'auto', 'max_depth': 10}\n",
      "-2926.320075 (133.482540) with: {'min_samples_leaf': 50, 'max_features': 'sqrt', 'max_depth': 20}\n",
      "-3001.631794 (153.043338) with: {'min_samples_leaf': 100, 'max_features': 'sqrt', 'max_depth': 15}\n",
      "-2908.662077 (129.264471) with: {'min_samples_leaf': 70, 'max_features': 'auto', 'max_depth': 5}\n",
      "-2913.229312 (126.435332) with: {'min_samples_leaf': 10, 'max_features': 'log2', 'max_depth': 20}\n",
      "-3429.431163 (145.564581) with: {'min_samples_leaf': 70, 'max_features': 'sqrt', 'max_depth': 5}\n",
      "-2994.623288 (120.670659) with: {'min_samples_leaf': 50, 'max_features': 'sqrt', 'max_depth': 10}\n",
      "Validation\n",
      "Mean Absolute Error : 31.554434209745367\n",
      "Root Mean Squared Error : 50.94918485229956\n",
      "R2 Score: 0.5530752123235838\n"
     ]
    }
   ],
   "source": [
    "# Tunning Parameters\n",
    "max_depth = [5, 10, 15, 20]\n",
    "max_features = ['log2', 'sqrt', 'auto']\n",
    "min_samples_leaf = [10, 50, 70, 100]\n",
    "param_grid = dict(max_depth=max_depth, max_features=max_features, \n",
    "                  min_samples_leaf=min_samples_leaf)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "random_search(DecisionTreeRegressor(random_state=8), param_grid, X_train, y_train, X_val, y_val, kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Training\n",
      "Mean Absolute Error : 30.2612396445677\n",
      "Root Mean Squared Error : 49.04630615408939\n",
      "R2 Score: 0.6058202509274686\n",
      "\n",
      "\n",
      "Validation\n",
      "Mean Absolute Error : 31.47499523679866\n",
      "Root Mean Squared Error : 50.748549752650256\n",
      "R2 Score: 0.5565882123513648\n",
      "\n",
      "[0.57549068 0.56771866 0.56552532 0.56252498 0.56295446]\n",
      "Mean score: 0.5668428178208071 max is 0.5754906781072666 and min 0.5625249779581796\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(max_depth=20, min_samples_leaf=50, random_state=8)\n",
    "fit_model(model,X_train,y_train,X_val,y_val,cross_val=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Conclusion\n",
    "\n",
    "We have a model which have maximum accuracy of 57% in and min accuracy of 56% terms of R2_score.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
